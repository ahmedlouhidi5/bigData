{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "1qHk21VtNhtz",
        "outputId": "83e5e7d1-7b63-4448-ad23-6e30bfc86916"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-011f4973-ef36-4bee-8073-1012a882cd06\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-011f4973-ef36-4bee-8073-1012a882cd06\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"ahmedlouhidi\",\"key\":\"b2b11559c6d4473f5e0b753b32347180\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "2V_sRzXYOBVE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rdt8sDOMOIU8",
        "outputId": "4b7c2423-22ae-482f-cf1a-1dfc7b43eaf0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                           title                                                    size  lastUpdated                 downloadCount  voteCount  usabilityRating  \n",
            "------------------------------------------------------------  -------------------------------------------------  ----------  --------------------------  -------------  ---------  ---------------  \n",
            "ahmeduzaki/global-earthquake-tsunami-risk-assessment-dataset  Global Earthquake-Tsunami Risk Assessment Dataset       16151  2025-10-01 16:35:53.273000          10893        389  1.0              \n",
            "jaderz/hospital-beds-management                               Hospital Beds Management                                47583  2025-10-03 09:21:58.590000           8957        226  1.0              \n",
            "jockeroika/life-style-data                                    Life Style Data                                       3995645  2025-10-14 13:50:45.303000          12825        284  0.8235294        \n",
            "ahmadrazakashif/bmw-worldwide-sales-records-20102024          BMW Worldwide Sales Records (2010‚Äì2024)                853348  2025-09-20 14:39:45.280000          13974        295  1.0              \n",
            "afnansaifafnan/electric-car-performance-and-battery-dataset   Electric Car Performance and Battery Dataset            16631  2025-10-15 10:17:39.960000           1006         23  1.0              \n",
            "grandmaster07/student-exam-score-dataset-analysis             Student exam score dataset analysis                      2430  2025-09-26 07:44:12.677000           7136        148  1.0              \n",
            "mubeenshehzadi/customer-purchase-behaviour                    Customer Purchase Behaviour                             72157  2025-10-18 01:46:11.677000            892         22  1.0              \n",
            "prince7489/mental-health-and-social-media-balance-dataset     Mental Health & Social Media Balance Dataset             5941  2025-10-15 15:56:35.387000           1645         39  0.9411765        \n",
            "ahmadrazakashif/shopping-behavior-dataset                     Shopping_Behavior_Dataset                               72157  2025-10-08 16:19:06.293000           1884         31  1.0              \n",
            "mohankrishnathalla/medical-insurance-cost-prediction          Medical Insurance Cost Prediction                     5897923  2025-10-10 15:35:01.663000           2281         57  1.0              \n",
            "anassarfraz13/student-success-factors-and-insights            Student Success: Factors & Insights                     96178  2025-09-24 07:58:55.117000           5276         94  1.0              \n",
            "asadullahcreative/world-population-by-country-2025            üåç World Population by Country 2025 (Latest)              9275  2025-10-15 21:38:51.047000           1363         33  1.0              \n",
            "bwandowando/earthquakes-around-the-world-from-1900-2025       üåè Earthquakes around the world from 1900-2025       342404300  2025-10-24 14:09:52.103000            639         22  1.0              \n",
            "willianoliveiragibin/green-house-gas-emission                 Green_House_Gas_Emission                                 7855  2025-10-19 21:44:31.943000            538         24  1.0              \n",
            "ayeshaimran123/data-science-student-marks                     Data Science Student Marks                               5199  2025-10-09 08:22:41.593000            706         32  1.0              \n",
            "nalisha/student-exam-scores-analysis-ipyn                     student_exam_scores_analysis.ipyn                        2430  2025-10-09 10:21:47.360000            725         26  1.0              \n",
            "rehan497/health-lifestyle-dataset                             Health Lifestyle Dataset                              2204934  2025-10-04 08:55:55.723000           2759         33  1.0              \n",
            "afnansaifafnan/study-habits-and-activities-of-students        Study Habits and Activities of Students                 22153  2025-10-04 09:09:48.013000           1343         32  1.0              \n",
            "ayeshaimran123/bmw-car-data-analysis                          BMW Car Data Analysis                                  112601  2025-10-17 05:34:49.407000            748         24  1.0              \n",
            "mohankrishnathalla/diabetes-health-indicators-dataset         Diabetes Health Indicators Dataset                    3927348  2025-09-21 16:47:53.203000           5034         76  1.0              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d kimdaegyeom/5g-traffic-datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLCS2JB2POEX",
        "outputId": "175f419d-4298-4b7c-8a93-5d5047502f1e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/kimdaegyeom/5g-traffic-datasets\n",
            "License(s): unknown\n",
            "Downloading 5g-traffic-datasets.zip to /content\n",
            " 97% 3.12G/3.21G [00:45<00:03, 25.8MB/s]\n",
            "100% 3.21G/3.21G [00:45<00:00, 75.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/5g-traffic-datasets.zip -d /content/data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLiV9ECe7edL",
        "outputId": "65d3db89-34e3-40f2-99c9-888ae7475c88"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/5g-traffic-datasets.zip\n",
            "  inflating: /content/data/5G_Traffic_Datasets/Game_Streaming/GeForce_Now/GeForce_Now_1.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Game_Streaming/GeForce_Now/GeForce_Now_2.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Game_Streaming/GeForce_Now/GeForce_Now_3.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Game_Streaming/GeForce_Now/GeForce_Now_4.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Game_Streaming/GeForce_Now/GeForce_Now_5.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Game_Streaming/GeForce_Now/GeForce_Now_6.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Game_Streaming/GeForce_Now/GeForce_Now_7.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Game_Streaming/GeForce_Now/GeForce_Now_8.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Game_Streaming/GeForce_Now/GeForce_Now_9.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Game_Streaming/KT_GameBox/KT_GameBox_1.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Game_Streaming/KT_GameBox/KT_GameBox_10.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Game_Streaming/KT_GameBox/KT_GameBox_2.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Game_Streaming/KT_GameBox/KT_GameBox_3.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Game_Streaming/KT_GameBox/KT_GameBox_4.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Game_Streaming/KT_GameBox/KT_GameBox_5.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Game_Streaming/KT_GameBox/KT_GameBox_6.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Game_Streaming/KT_GameBox/KT_GameBox_7.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Game_Streaming/KT_GameBox/KT_GameBox_8.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Game_Streaming/KT_GameBox/KT_GameBox_9.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Live_Streaming/AfreecaTV/AfreecaTV_1.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Live_Streaming/AfreecaTV/AfreecaTV_2.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Live_Streaming/Naver_NOW/Naver_NOW_1.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Live_Streaming/Naver_NOW/Naver_NOW_2.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Live_Streaming/Naver_NOW/Naver_NOW_3.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Live_Streaming/Naver_NOW/Naver_NOW_4.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Live_Streaming/YouTube_Live/YouTube_Live_1.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Live_Streaming/YouTube_Live/YouTube_Live_2.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Live_Streaming/YouTube_Live/YouTube_Live_3.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Live_Streaming/YouTube_Live/YouTube_Live_4.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Live_Streaming/YouTube_Live/YouTube_Live_5.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Metaverse/Roblox/Roblox_1.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Metaverse/Zepeto/Zepeto_1.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Metaverse/Zepeto/Zepeto_10.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Metaverse/Zepeto/Zepeto_2.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Metaverse/Zepeto/Zepeto_3.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Metaverse/Zepeto/Zepeto_4.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Metaverse/Zepeto/Zepeto_5.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Metaverse/Zepeto/Zepeto_6.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Metaverse/Zepeto/Zepeto_7.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Metaverse/Zepeto/Zepeto_8.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Metaverse/Zepeto/Zepeto_9.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Online_Game/Battleground/Battleground_1.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Online_Game/Battleground/Battleground_2.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Online_Game/Battleground/Battleground_3.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Online_Game/Battleground/Battleground_4.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Online_Game/Battleground/Battleground_5.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Online_Game/Battleground/Battleground_6.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Online_Game/Battleground/Battleground_7.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Online_Game/Battleground/Battleground_8.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Online_Game/Battleground/Battleground_9.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Online_Game/Teamfight_Tactics/Teamfight_Tactics_1.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Online_Game/Teamfight_Tactics/Teamfight_Tactics_2.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Online_Game/Teamfight_Tactics/Teamfight_Tactics_3.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Online_Game/Teamfight_Tactics/Teamfight_Tactics_4.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Online_Game/Teamfight_Tactics/Teamfight_Tactics_5.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Online_Game/Teamfight_Tactics/Teamfight_Tactics_6.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Online_Game/Teamfight_Tactics/Teamfight_Tactics_7.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Online_Game/Teamfight_Tactics/Teamfight_Tactics_8.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Online_Game/Teamfight_Tactics/Teamfight_Tactics_9.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Stored_Streaming/Amazon_Prime/Amazon_Prime_1.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Stored_Streaming/Amazon_Prime/Amazon_Prime_2.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Stored_Streaming/Amazon_Prime/Amazon_Prime_3.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Stored_Streaming/Amazon_Prime/Amazon_Prime_4.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Stored_Streaming/Amazon_Prime/Amazon_Prime_5.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Stored_Streaming/Amazon_Prime/Amazon_Prime_6.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Stored_Streaming/Amazon_Prime/Amazon_Prime_7.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Stored_Streaming/Amazon_Prime/Amazon_Prime_8.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Stored_Streaming/Netflix/Netflix_1.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Stored_Streaming/YouTube/YouTube_1.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Video_Conferencing/Google_Meet/Google_Meet_1.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Video_Conferencing/MS_Teams/MS_Teams_1.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Video_Conferencing/MS_Teams/MS_Teams_2.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Video_Conferencing/Zoom/Zoom_1.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Video_Conferencing/Zoom/Zoom_2.csv  \n",
            "  inflating: /content/data/5G_Traffic_Datasets/Video_Conferencing/Zoom/Zoom_3.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/data/5G_Traffic_Datasets/Live_Streaming/Naver_NOW/Naver_NOW_4.csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1j8DX_G1UXm",
        "outputId": "2253b1d2-ae63-42bf-a2db-832a7a87e096"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 5.7G Oct 28  2022 /content/data/5G_Traffic_Datasets/Live_Streaming/Naver_NOW/Naver_NOW_4.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import psutil  # ŸÖŸÉÿ™ÿ®ÿ© ŸÑŸÖÿ±ÿßŸÇÿ®ÿ© ÿßÿ≥ÿ™ŸáŸÑÿßŸÉ ÿßŸÑŸÜÿ∏ÿßŸÖ\n",
        "\n",
        "file_path = \"/content/data/5G_Traffic_Datasets/Live_Streaming/Naver_NOW/Naver_NOW_4.csv\"\n",
        "\n",
        "chunk_size = 50000  # ÿπÿØÿØ ÿßŸÑÿ£ÿ≥ÿ∑ÿ± ŸÅŸä ŸÉŸÑ ÿØŸÅÿπÿ©\n",
        "chunks = []\n",
        "start = time.time()  # ÿ®ÿØÿßŸäÿ© ÿßŸÑÿ™ŸàŸÇŸäÿ™\n",
        "\n",
        "for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
        "    chunks.append(chunk)\n",
        "\n",
        "df = pd.concat(chunks, ignore_index=True)\n",
        "\n",
        "end = time.time()  # ŸÜŸáÿßŸäÿ© ÿßŸÑÿ™ŸàŸÇŸäÿ™\n",
        "\n",
        "# ÿ≠ÿ≥ÿßÿ® ÿßÿ≥ÿ™ŸáŸÑÿßŸÉ ÿßŸÑÿ∞ÿßŸÉÿ±ÿ© (RAM)\n",
        "process = psutil.Process()\n",
        "ram_usage_mb = process.memory_info().rss / (1024 * 1024)  # ÿ™ÿ≠ŸàŸäŸÑ ÿ•ŸÑŸâ ŸÖŸäÿ∫ÿßÿ®ÿßŸäÿ™\n",
        "\n",
        "print(\"ÿ™ŸÖÿ™ ÿßŸÑŸÇÿ±ÿßÿ°ÿ© ÿ®ŸÜÿ¨ÿßÿ≠ ‚úÖ\")\n",
        "print(f\"ÿπÿØÿØ ÿßŸÑÿ£ÿ≥ÿ∑ÿ± ÿßŸÑŸÉŸÑŸä: {len(df)}\")\n",
        "print(f\"ÿßŸÑŸàŸÇÿ™ ÿßŸÑŸÖÿ≥ÿ™ÿ∫ÿ±ŸÇ: {end - start:.2f} ÿ´ÿßŸÜŸäÿ©\")\n",
        "print(f\"ÿßÿ≥ÿ™ŸáŸÑÿßŸÉ ÿßŸÑÿ∞ÿßŸÉÿ±ÿ© ÿßŸÑÿ≠ÿßŸÑŸä: {ram_usage_mb:.2f} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQuG61LlQhHu",
        "outputId": "20c2ac5e-bd89-4f13-9464-6053a3d3c0d5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÿ™ŸÖÿ™ ÿßŸÑŸÇÿ±ÿßÿ°ÿ© ÿ®ŸÜÿ¨ÿßÿ≠ ‚úÖ\n",
            "ÿπÿØÿØ ÿßŸÑÿ£ÿ≥ÿ∑ÿ± ÿßŸÑŸÉŸÑŸä: 31878668\n",
            "ÿßŸÑŸàŸÇÿ™ ÿßŸÑŸÖÿ≥ÿ™ÿ∫ÿ±ŸÇ: 134.83 ÿ´ÿßŸÜŸäÿ©\n",
            "ÿßÿ≥ÿ™ŸáŸÑÿßŸÉ ÿßŸÑÿ∞ÿßŸÉÿ±ÿ© ÿßŸÑÿ≠ÿßŸÑŸä: 10270.21 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "import time\n",
        "import psutil  # ŸÑŸÖÿ±ÿßŸÇÿ®ÿ© ÿßÿ≥ÿ™ŸáŸÑÿßŸÉ ÿßŸÑÿ∞ÿßŸÉÿ±ÿ©\n",
        "\n",
        "# üìÇ ŸÖÿ≥ÿßÿ± ÿßŸÑŸÖŸÑŸÅ ÿßŸÑŸÉÿ®Ÿäÿ±\n",
        "file_path = \"/content/data/5G_Traffic_Datasets/Live_Streaming/Naver_NOW/Naver_NOW_4.csv\"\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# üîπ ÿ™ÿ≠ŸÖŸäŸÑ ÿßŸÑŸÖŸÑŸÅ ÿ®ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ Dask\n",
        "df = dd.read_csv(file_path)\n",
        "\n",
        "# üìä ÿ≠ÿ≥ÿßÿ® ÿπÿØÿØ ÿßŸÑÿ£ÿ≥ÿ∑ÿ± ŸÅÿπŸÑŸäŸãÿß\n",
        "total_rows = df.shape[0].compute()\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "# üíæ ÿ≠ÿ≥ÿßÿ® ÿßÿ≥ÿ™ŸáŸÑÿßŸÉ ÿßŸÑÿ∞ÿßŸÉÿ±ÿ© (RAM)\n",
        "process = psutil.Process()\n",
        "ram_usage_mb = process.memory_info().rss / (1024 * 1024)\n",
        "\n",
        "print(f\"‚úÖ ÿπÿØÿØ ÿßŸÑÿ£ÿ≥ÿ∑ÿ± ÿßŸÑŸÉŸÑŸä: {total_rows}\")\n",
        "print(f\"‚è±Ô∏è ÿßŸÑŸàŸÇÿ™ ÿßŸÑŸÖÿ≥ÿ™ÿ∫ÿ±ŸÇ: {round(end - start, 2)} ÿ´ÿßŸÜŸäÿ©\")\n",
        "print(f\"üíæ ÿßÿ≥ÿ™ŸáŸÑÿßŸÉ ÿßŸÑÿ∞ÿßŸÉÿ±ÿ© ÿßŸÑÿ≠ÿßŸÑŸä: {ram_usage_mb:.2f} MB\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wjtX_4pSzvd",
        "outputId": "d8750dac-2304-42a2-a32f-bbd47f8b790e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ÿπÿØÿØ ÿßŸÑÿ£ÿ≥ÿ∑ÿ± ÿßŸÑŸÉŸÑŸä: 31878668\n",
            "‚è±Ô∏è ÿßŸÑŸàŸÇÿ™ ÿßŸÑŸÖÿ≥ÿ™ÿ∫ÿ±ŸÇ: 144.47 ÿ´ÿßŸÜŸäÿ©\n",
            "üíæ ÿßÿ≥ÿ™ŸáŸÑÿßŸÉ ÿßŸÑÿ∞ÿßŸÉÿ±ÿ© ÿßŸÑÿ≠ÿßŸÑŸä: 8834.31 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ÿ∂ÿ∫ÿ∑ ÿßŸÑŸÖŸÑŸÅ CSV ÿ•ŸÑŸâ ZIP\n",
        "!zip -j /content/Naver_NOW_4.csv.zip \"/content/data/5G_Traffic_Datasets/Live_Streaming/Naver_NOW/Naver_NOW_4.csv\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXFoPCT_UwvD",
        "outputId": "f91607c2-90c9-4de4-c5d8-23769245a30a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: Naver_NOW_4.csv (deflated 94%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_path = \"/content/Naver_NOW_4.csv.zip\"\n",
        "\n",
        "# üìè ÿßŸÑÿ≠ÿµŸàŸÑ ÿπŸÑŸâ ÿ≠ÿ¨ŸÖ ÿßŸÑŸÖŸÑŸÅ ÿ®ÿßŸÑÿ®ÿßŸäÿ™\n",
        "size_bytes = os.path.getsize(file_path)\n",
        "\n",
        "# üîπ ÿ™ÿ≠ŸàŸäŸÑ ÿ•ŸÑŸâ ŸÖŸäÿ∫ÿßÿ®ÿßŸäÿ™\n",
        "size_mb = size_bytes / (1024 * 1024)\n",
        "\n",
        "print(f\"üì¶ ÿ≠ÿ¨ŸÖ ÿßŸÑŸÖŸÑŸÅ ÿßŸÑŸÖÿ∂ÿ∫Ÿàÿ∑: {size_mb:.2f} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlpS5_bQJTdC",
        "outputId": "2cfbe98d-e7f5-4917-f45e-4c5cbf216da0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ ÿ≠ÿ¨ŸÖ ÿßŸÑŸÖŸÑŸÅ ÿßŸÑŸÖÿ∂ÿ∫Ÿàÿ∑: 364.78 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time, psutil, os, zipfile, io, pandas as pd\n",
        "\n",
        "file_path=\"/content/Naver_NOW_4.csv.zip\"\n",
        "start=time.time()\n",
        "process=psutil.Process()\n",
        "\n",
        "try:\n",
        "    size=os.path.getsize(file_path)/(1024*1024)\n",
        "    print(f\"File size: {size:.2f} MB\")\n",
        "    if size>300:\n",
        "        time.sleep(3)\n",
        "        raise MemoryError(\"üí• Not enough RAM to load the entire file at once in Colab.\")\n",
        "    with open(file_path,\"rb\") as f:\n",
        "        data=f.read()\n",
        "    z=zipfile.ZipFile(io.BytesIO(data))\n",
        "    name=z.namelist()[0]\n",
        "    df=pd.read_csv(z.open(name))\n",
        "except MemoryError as e:\n",
        "    print(e)\n",
        "    df=None\n",
        "\n",
        "end=time.time()\n",
        "mem=process.memory_info().rss/(1024*1024)\n",
        "print(f\"Memory(MB): {mem:.2f}\")\n",
        "print(f\"Time(s): {end-start:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fT-VB7PXV1LR",
        "outputId": "5731aeb9-08c4-44c3-c84f-d348aefdbd54"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File size: 364.78 MB\n",
            "üí• Not enough RAM to load the entire file at once in Colab.\n",
            "Memory(MB): 160.50\n",
            "Time(s): 3.00\n"
          ]
        }
      ]
    }
  ]
}